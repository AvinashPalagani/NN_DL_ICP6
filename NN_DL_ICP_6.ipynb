{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AEwBmpZof2WDDrNP6ipLC8LWRwiItEkx",
      "authorship_tag": "ABX9TyOhe1zE8u5d1Va4NVUsU7Xy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvinashPalagani/NN_DL_ICP6/blob/main/NN_DL_ICP_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxuTnbPFwRVC",
        "outputId": "569f05f4-bf12-4669-e8cc-a02daa14a663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Predicting the diabetes disease\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/diabetes.csv'"
      ],
      "metadata": {
        "id": "SC0IrEyLwsxk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYDHWzdFJEi6",
        "outputId": "23ffcfa0-91ce-4e0e-a11d-eee1034262c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 3ms/step - loss: 73.9138 - acc: 0.3385\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 57.3484 - acc: 0.3385\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 40.5028 - acc: 0.3385\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 25.5487 - acc: 0.3333\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 13.5688 - acc: 0.3455\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 6.9931 - acc: 0.4948\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 4.6600 - acc: 0.6042\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.2909 - acc: 0.5868\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.8482 - acc: 0.6094\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.5780 - acc: 0.6042\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.4241 - acc: 0.6059\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.2886 - acc: 0.6128\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 2.1672 - acc: 0.6076\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.0677 - acc: 0.6128\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.9514 - acc: 0.6198\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.8727 - acc: 0.6198\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.7609 - acc: 0.6233\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.7032 - acc: 0.6302\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.6413 - acc: 0.6094\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.5812 - acc: 0.6267\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.4865 - acc: 0.6111\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4271 - acc: 0.6476\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.3737 - acc: 0.6215\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.3265 - acc: 0.6163\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2640 - acc: 0.6441\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.2461 - acc: 0.6458\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1882 - acc: 0.6215\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.1172 - acc: 0.6337\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0695 - acc: 0.6372\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0443 - acc: 0.6458\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9744 - acc: 0.6458\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.9318 - acc: 0.6406\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8920 - acc: 0.6632\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8820 - acc: 0.6562\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.8370 - acc: 0.6285\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8221 - acc: 0.6458\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7933 - acc: 0.6580\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7592 - acc: 0.6562\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7448 - acc: 0.6632\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7201 - acc: 0.6510\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7101 - acc: 0.6580\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6919 - acc: 0.6771\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6722 - acc: 0.6649\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6659 - acc: 0.6753\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6985 - acc: 0.6615\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6569 - acc: 0.6632\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6372 - acc: 0.6875\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6698 - acc: 0.6979\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6521 - acc: 0.6649\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6489 - acc: 0.6753\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6493 - acc: 0.6562\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6397 - acc: 0.6910\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6034 - acc: 0.7066\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6568 - acc: 0.6684\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6046 - acc: 0.6944\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6139 - acc: 0.7014\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - acc: 0.6771\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6079 - acc: 0.6944\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5972 - acc: 0.7066\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5951 - acc: 0.7066\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6099 - acc: 0.6840\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6540 - acc: 0.6806\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - acc: 0.6753\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5926 - acc: 0.7066\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5886 - acc: 0.7135\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5927 - acc: 0.7153\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6451 - acc: 0.6632\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6162 - acc: 0.6962\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5905 - acc: 0.6927\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6011 - acc: 0.7240\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5850 - acc: 0.7049\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5927 - acc: 0.6997\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5838 - acc: 0.7014\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - acc: 0.6979\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5949 - acc: 0.6788\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5782 - acc: 0.7153\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5717 - acc: 0.7153\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5800 - acc: 0.6997\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6022 - acc: 0.6944\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5782 - acc: 0.7083\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5983 - acc: 0.7049\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6640 - acc: 0.6389\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6195 - acc: 0.6979\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - acc: 0.7135\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5829 - acc: 0.7083\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5976 - acc: 0.7049\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5722 - acc: 0.7170\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5963 - acc: 0.7257\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5989 - acc: 0.7135\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5708 - acc: 0.7222\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5736 - acc: 0.7240\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5741 - acc: 0.7153\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6016 - acc: 0.7014\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6626 - acc: 0.6823\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6208 - acc: 0.7205\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5624 - acc: 0.7240\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5750 - acc: 0.7170\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5718 - acc: 0.7309\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5764 - acc: 0.7240\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5840 - acc: 0.7083\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                180       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.6192 - acc: 0.6927\n",
            "[0.6191532015800476, 0.6927083134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. a. Add more Dense layers to the existing code and check how the accuracy changes."
      ],
      "metadata": {
        "id": "JLbXU0BBQfhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer with input\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, activation='relu')) # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtlNMxTqQgfV",
        "outputId": "cda7acc1-8d81-4012-cd21-09ed9bb5d09d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 20)                180       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2301 (8.99 KB)\n",
            "Trainable params: 2301 (8.99 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 1.8070 - acc: 0.7240\n",
            "[1.807026982307434, 0.7239583134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Change the data source to Breast Cancer dataset * available in the source code folder and make required changes. Report accuracy of the model."
      ],
      "metadata": {
        "id": "RiT7lqxvQydv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/breastcancer.csv'\n",
        "\n",
        "#Importing packages for creating arrays\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Importing packages to convert Categorical data into Numerical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Importing packages for splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Importing packages for keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "\n",
        "#Loading the Dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=0)"
      ],
      "metadata": {
        "id": "3FqCplcSQz3V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "EHo5iAeyQ8T0",
        "outputId": "7ad3b73b-504b-473e-f572-53809c3f333d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0      842302         M        17.99         10.38          122.80     1001.0   \n",
              "1      842517         M        20.57         17.77          132.90     1326.0   \n",
              "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3    84348301         M        11.42         20.38           77.58      386.1   \n",
              "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
              "..        ...       ...          ...           ...             ...        ...   \n",
              "564    926424         M        21.56         22.39          142.00     1479.0   \n",
              "565    926682         M        20.13         28.25          131.20     1261.0   \n",
              "566    926954         M        16.60         28.08          108.30      858.1   \n",
              "567    927241         M        20.60         29.33          140.10     1265.0   \n",
              "568     92751         B         7.76         24.54           47.92      181.0   \n",
              "\n",
              "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0            0.11840           0.27760         0.30010              0.14710   \n",
              "1            0.08474           0.07864         0.08690              0.07017   \n",
              "2            0.10960           0.15990         0.19740              0.12790   \n",
              "3            0.14250           0.28390         0.24140              0.10520   \n",
              "4            0.10030           0.13280         0.19800              0.10430   \n",
              "..               ...               ...             ...                  ...   \n",
              "564          0.11100           0.11590         0.24390              0.13890   \n",
              "565          0.09780           0.10340         0.14400              0.09791   \n",
              "566          0.08455           0.10230         0.09251              0.05302   \n",
              "567          0.11780           0.27700         0.35140              0.15200   \n",
              "568          0.05263           0.04362         0.00000              0.00000   \n",
              "\n",
              "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0    ...          17.33           184.60      2019.0           0.16220   \n",
              "1    ...          23.41           158.80      1956.0           0.12380   \n",
              "2    ...          25.53           152.50      1709.0           0.14440   \n",
              "3    ...          26.50            98.87       567.7           0.20980   \n",
              "4    ...          16.67           152.20      1575.0           0.13740   \n",
              "..   ...            ...              ...         ...               ...   \n",
              "564  ...          26.40           166.10      2027.0           0.14100   \n",
              "565  ...          38.25           155.00      1731.0           0.11660   \n",
              "566  ...          34.12           126.70      1124.0           0.11390   \n",
              "567  ...          39.42           184.60      1821.0           0.16500   \n",
              "568  ...          30.37            59.16       268.6           0.08996   \n",
              "\n",
              "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0              0.66560           0.7119                0.2654          0.4601   \n",
              "1              0.18660           0.2416                0.1860          0.2750   \n",
              "2              0.42450           0.4504                0.2430          0.3613   \n",
              "3              0.86630           0.6869                0.2575          0.6638   \n",
              "4              0.20500           0.4000                0.1625          0.2364   \n",
              "..                 ...              ...                   ...             ...   \n",
              "564            0.21130           0.4107                0.2216          0.2060   \n",
              "565            0.19220           0.3215                0.1628          0.2572   \n",
              "566            0.30940           0.3403                0.1418          0.2218   \n",
              "567            0.86810           0.9387                0.2650          0.4087   \n",
              "568            0.06444           0.0000                0.0000          0.2871   \n",
              "\n",
              "     fractal_dimension_worst  Unnamed: 32  \n",
              "0                    0.11890          NaN  \n",
              "1                    0.08902          NaN  \n",
              "2                    0.08758          NaN  \n",
              "3                    0.17300          NaN  \n",
              "4                    0.07678          NaN  \n",
              "..                       ...          ...  \n",
              "564                  0.07115          NaN  \n",
              "565                  0.06637          NaN  \n",
              "566                  0.07820          NaN  \n",
              "567                  0.12400          NaN  \n",
              "568                  0.07039          NaN  \n",
              "\n",
              "[569 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7c3c9e3-2cb2-4487-9605-498fa447e573\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7c3c9e3-2cb2-4487-9605-498fa447e573')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7c3c9e3-2cb2-4487-9605-498fa447e573 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7c3c9e3-2cb2-4487-9605-498fa447e573');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7f90e30-0bc5-442c-9645-f3d2ebe954e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7f90e30-0bc5-442c-9645-f3d2ebe954e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7f90e30-0bc5-442c-9645-f3d2ebe954e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Categorical data into Numerical Using Label Encoding\n",
        "le=LabelEncoder()\n",
        "dataset['diagnosis'] = le.fit_transform(dataset['diagnosis'])\n",
        "\n",
        "\n",
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpBOE8L3RBfz",
        "outputId": "3ad10eb4-b073-4e89-99c0-40c0f5f73d29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    int64  \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(2)\n",
            "memory usage: 146.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into Feature Matrix & Label Matrix\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset.iloc[:,2:32], dataset.iloc[:,1], test_size=0.25, random_state=87)\n",
        "\n",
        "\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fec8tSwWRHLN",
        "outputId": "72123b83-68c4-4096-9ffe-981b4c584250"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1481 (5.79 KB)\n",
            "Trainable params: 1481 (5.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2626 - acc: 0.8881\n",
            "[0.26264557242393494, 0.8881118893623352]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Normalize the data before feeding the data to the model and check how the normalization change your accuracy"
      ],
      "metadata": {
        "id": "aZVZ6sciRN_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages for Normalization\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "gFZknvj3ROy2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc']) # compilation\n",
        "\n",
        "sc = StandardScaler() #Create Model\n",
        "X_train = sc.fit_transform(X_train) #Fit to data, then transform it.\n",
        "X_test = sc.transform(X_test) # Perform standardization by centering and scaling\n",
        "\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,verbose=0, initial_epoch=0) # Training\n",
        "print(my_first_nn.summary()) #Summary\n",
        "print(my_first_nn.evaluate(X_test, Y_test)) #Evaluating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj7q7P0oRWw1",
        "outputId": "21eeb090-5cb0-4771-8817-f47b48783887"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 20)                620       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641 (2.50 KB)\n",
            "Trainable params: 641 (2.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1235 - acc: 0.9720\n",
            "[0.12349341809749603, 0.9720279574394226]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUE 2"
      ],
      "metadata": {
        "id": "woiovrJwRfaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "#scale data\n",
        "train_data /=255.0\n",
        "test_data /=255.0\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9cerNldRhhj",
        "outputId": "90968724-71f7-493e-92ec-19b43454d545"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Plot the loss and accuracy for both training data and validation data using the history object in the source code."
      ],
      "metadata": {
        "id": "roFLunGfRt1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Zxv6u6Ruxi",
        "outputId": "3f9cd706-3093-4d79-e31b-ba95b8ce70ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 9s 35ms/step - loss: 0.2941 - accuracy: 0.9105 - val_loss: 0.1746 - val_accuracy: 0.9473\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0990 - accuracy: 0.9693 - val_loss: 0.1247 - val_accuracy: 0.9615\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0622 - accuracy: 0.9808 - val_loss: 0.0915 - val_accuracy: 0.9712\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 7s 28ms/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.1107 - val_accuracy: 0.9675\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 10s 43ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.0693 - val_accuracy: 0.9791\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0841 - val_accuracy: 0.9733\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0652 - val_accuracy: 0.9828\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0695 - val_accuracy: 0.9810\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0620 - val_accuracy: 0.9841\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 12s 49ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0912 - val_accuracy: 0.9790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n",
        "\n",
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2dMoY8LSB9d",
        "outputId": "be9b8356-ba85-42b2-ba10-adecb09a1276"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9790\n",
            "Evaluation result on Test Data : Loss = 0.09120582789182663, accuracy = 0.9789999723434448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_accuracy','loss','val_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ql8tK3IdSO_Z",
        "outputId": "1f7b21d0-4257-497e-d9fa-0f5216a4f316"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Plot one of the images in the test data, and then do inferencing to check what is the prediction of the model on that single image."
      ],
      "metadata": {
        "id": "ORZWQ3SsSTuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_data[0].reshape(28,28))\n",
        "print(\"predicted label:\",model.predict(test_data[0].reshape(1,784)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "JgxsiynYSUct",
        "outputId": "afd378c1-c744-48ba-ebb4-3ea093f8c14c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 161ms/step\n",
            "predicted label: [[3.5071298e-13 3.8538259e-10 4.6909154e-11 1.1048080e-09 7.0909646e-13\n",
            "  3.8157715e-13 7.7962114e-16 1.0000000e+00 5.1393454e-13 4.9948299e-09]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. We had used 2 hidden layers and Relu activation. Try to change the number of hidden layer and the activation to tanh or sigmoid and see what happens."
      ],
      "metadata": {
        "id": "jS92LBEjSj_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#increasing the number of hidden layers to 6\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss1, test_acc1] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with 4 hidden layers: Loss = {}, accuracy = {}\".format(test_loss1, test_acc1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22Vqm8-dSk0Q",
        "outputId": "da58635e-be76-4439-c4fd-266e28b04a9d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 21s 84ms/step - loss: 0.5146 - accuracy: 0.8383 - val_loss: 0.1597 - val_accuracy: 0.9522\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 25s 106ms/step - loss: 0.1333 - accuracy: 0.9617 - val_loss: 0.0984 - val_accuracy: 0.9720\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 26s 112ms/step - loss: 0.0819 - accuracy: 0.9758 - val_loss: 0.1542 - val_accuracy: 0.9558\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 27s 113ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.1004 - val_accuracy: 0.9743\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 27s 113ms/step - loss: 0.0424 - accuracy: 0.9877 - val_loss: 0.0781 - val_accuracy: 0.9800\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 19s 79ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.1256 - val_accuracy: 0.9710\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0708 - val_accuracy: 0.9829\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 19s 82ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0766 - val_accuracy: 0.9799\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0765 - val_accuracy: 0.9825\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.1000 - val_accuracy: 0.9785\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1000 - accuracy: 0.9785\n",
            "Evaluation result on Test Data with 4 hidden layers: Loss = 0.10001084953546524, accuracy = 0.9785000085830688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#All hidden layers with tanh activation\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='tanh', input_shape=(dimData,)))\n",
        "model.add(Dense(612, activation='tanh'))\n",
        "model.add(Dense(712, activation='tanh'))\n",
        "model.add(Dense(812, activation='tanh'))\n",
        "model.add(Dense(712, activation='tanh'))\n",
        "model.add(Dense(812, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss2, test_acc2] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data with tanh activation: Loss = {}, accuracy = {}\".format(test_loss2, test_acc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Knly-8SwfM",
        "outputId": "ab2b92fd-d1a5-436c-88a6-79acff1bd4ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 32s 132ms/step - loss: 1.0542 - accuracy: 0.7417 - val_loss: 0.3856 - val_accuracy: 0.8853\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 32s 136ms/step - loss: 0.2744 - accuracy: 0.9207 - val_loss: 0.1768 - val_accuracy: 0.9479\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 32s 135ms/step - loss: 0.1781 - accuracy: 0.9474 - val_loss: 0.2359 - val_accuracy: 0.9335\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 33s 140ms/step - loss: 0.1318 - accuracy: 0.9607 - val_loss: 0.1548 - val_accuracy: 0.9582\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 32s 136ms/step - loss: 0.1039 - accuracy: 0.9691 - val_loss: 0.1630 - val_accuracy: 0.9542\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 32s 136ms/step - loss: 0.0817 - accuracy: 0.9746 - val_loss: 0.1780 - val_accuracy: 0.9531\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 30s 130ms/step - loss: 0.0694 - accuracy: 0.9788 - val_loss: 0.1153 - val_accuracy: 0.9672\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 30s 130ms/step - loss: 0.0542 - accuracy: 0.9830 - val_loss: 0.1330 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 34s 144ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.1098 - val_accuracy: 0.9733\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 32s 136ms/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 0.1254 - val_accuracy: 0.9698\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1254 - accuracy: 0.9698\n",
            "Evaluation result on Test Data with tanh activation: Loss = 0.12536503374576569, accuracy = 0.9697999954223633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Run the same code without scaling the images and check the performance?"
      ],
      "metadata": {
        "id": "HFVqg9rsS-0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images,train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_images.shape[1:])\n",
        "#process the data\n",
        "#1. convert each image of shape 28*28 to 784 dimensional which will be fed to the network as a single feature\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "# print(dimData)\n",
        "train_data = train_images.reshape(train_images.shape[0],dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0],dimData)\n",
        "\n",
        "#convert data to float and scale values between 0 and 1\n",
        "train_data = train_data.astype('float')\n",
        "test_data = test_data.astype('float')\n",
        "\n",
        "#change the labels frominteger to one-hot encoding. to_categorical is doing the same thing as LabelEncoder()\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "#creating network\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=10, verbose=1,\n",
        "                   validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "[test_loss3, test_acc3] = model.evaluate(test_data, test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data without scaling: Loss = {}, accuracy = {}\".format(test_loss3, test_acc3))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74BCUmtATAc2",
        "outputId": "921033c4-44f7-47e0-b0fc-bd3822b6df9b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 8s 30ms/step - loss: 6.0635 - accuracy: 0.8742 - val_loss: 0.5006 - val_accuracy: 0.9436\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.4239 - accuracy: 0.9477 - val_loss: 0.4726 - val_accuracy: 0.9424\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.2493 - accuracy: 0.9611 - val_loss: 0.4424 - val_accuracy: 0.9441\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.1991 - accuracy: 0.9665 - val_loss: 0.3461 - val_accuracy: 0.9497\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.1675 - accuracy: 0.9719 - val_loss: 0.2745 - val_accuracy: 0.9605\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.1384 - accuracy: 0.9760 - val_loss: 0.4019 - val_accuracy: 0.9587\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.1378 - accuracy: 0.9785 - val_loss: 0.3039 - val_accuracy: 0.9666\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.1248 - accuracy: 0.9805 - val_loss: 0.3319 - val_accuracy: 0.9620\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.1108 - accuracy: 0.9836 - val_loss: 0.3201 - val_accuracy: 0.9672\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.1172 - accuracy: 0.9837 - val_loss: 0.3001 - val_accuracy: 0.9730\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3001 - accuracy: 0.9730\n",
            "Evaluation result on Test Data without scaling: Loss = 0.30011579394340515, accuracy = 0.9729999899864197\n"
          ]
        }
      ]
    }
  ]
}